{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI544 HW4\n",
    "Yuhang Xiao - 6913860906 - yxiao776@usc.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment requirements:\n",
    "- Python 3.12.1\n",
    "- Numpy\n",
    "- Pandas\n",
    "- torch\n",
    "- tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Bidirectional LSTM model\n",
    "Implemented and trained Bi-LSTM model according to the requirements.\n",
    "\n",
    "Validation statistics on dev data:\n",
    "- precision: 85.01%\n",
    "- recall: 76.52% \n",
    "- F1 score: 80.54%\n",
    "\n",
    "The F1 score is reasonable compared to the reference 77%.\n",
    "\n",
    "#### Using GloVe word embeddings\n",
    "Used the pretrained GloVe embeddings to help train the model. Because Glove is case-insensitive, I didn't freeze the embeddings and allowed the fine-tuning because NER is case-sensitive.\n",
    "\n",
    "Validation statistics on dev data:\n",
    "- precision: 90.67%\n",
    "- recall: 90.95%\n",
    "- F1 score: 90.81%\n",
    "\n",
    "The F1 score is reasonable compared to the reference 88%.\n",
    "\n",
    "### Bonus: LSTM-CNN model\n",
    "To add the char info into the model. I padded each char of each word to conform to the longest sequence and longest word in each batch. I only added one single cnn layer with a context window of 3 to perform convolutions on chars of each word. Then, a maxpool is utilized to squeeze the word_len dim and let each word's char embeddings could be concatenated to the end of the word embeddings in the embedding_dim dimension. The concatenated features could then be feeded into LSTM to make final predictions.\n",
    "\n",
    "Validation statistics on dev data:\n",
    "- precision: 91.18%\n",
    "- recall: 92.68%\n",
    "- F1 score: 91.92%\n",
    "\n",
    "By adding the char info, the performance of the model is improved on all three metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path, test=False):\n",
    "    sents = []\n",
    "    tags = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            try:\n",
    "                if test:\n",
    "                    id, word = line.strip().split(' ')\n",
    "                    if id == '1':\n",
    "                        sents.append(sent)\n",
    "                        sent = []\n",
    "                    sent.append(word)\n",
    "                else:\n",
    "                    id, word, pred = line.strip().split(' ')\n",
    "                    if id == '1':\n",
    "                        sents.append(sent)\n",
    "                        tags.append(tag)\n",
    "                        sent = []\n",
    "                        tag = []\n",
    "                    sent.append(word)\n",
    "                    tag.append(pred)\n",
    "            except Exception as e:\n",
    "                if line.strip() == '':\n",
    "                    continue\n",
    "                if isinstance(e, UnboundLocalError):\n",
    "                    sent = [word]\n",
    "                    tag = [pred] if not test else []\n",
    "                    continue\n",
    "                raise e\n",
    "    return sents, tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_train, tags_train = read_data('data/train')\n",
    "sents_dev, tags_dev = read_data('data/dev')\n",
    "word_id = {}\n",
    "word_id['<pad>'] = 0\n",
    "word_id['<unk>'] = 1\n",
    "tag_id = {'<pad>': 0}\n",
    "word_lookup = {0: '<pad>', 1: '<unk>'}\n",
    "tag_lookup = {0: '<pad>'}\n",
    "sents = sents_train + sents_dev\n",
    "tags = tags_train + tags_dev\n",
    "for i in range(len(sents)):\n",
    "    for j in range(len(sents[i])):\n",
    "        word = sents[i][j]\n",
    "        tag = tags[i][j]\n",
    "        if word not in word_id:\n",
    "            word_id[word] = len(word_id)\n",
    "            word_lookup[word_id[word]] = word\n",
    "        if tag not in tag_id:\n",
    "            tag_id[tag] = len(tag_id)\n",
    "            tag_lookup[tag_id[tag]] = tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sent, word_id):\n",
    "    tokenized_sent = []\n",
    "    for word in sent:\n",
    "        if word in word_id:\n",
    "            tokenized_sent.append(word_id[word])\n",
    "        else:\n",
    "            tokenized_sent.append(word_id['<unk>'])\n",
    "    return tokenized_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    from torch.nn.utils.rnn import pad_sequence\n",
    "    if isinstance(batch[0], tuple):\n",
    "        # batch.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "        sents, tags = zip(*batch)\n",
    "        lengths = [len(sent) for sent in sents]\n",
    "        sents = pad_sequence(sents, batch_first=True, padding_value=word_id['<pad>']).long()\n",
    "        tags = pad_sequence(tags, batch_first=True).long()\n",
    "        return sents, torch.LongTensor(lengths), tags\n",
    "    else:\n",
    "        # batch.sort(key=lambda x: len(x), reverse=True)\n",
    "        sents = batch\n",
    "        lengths = [len(sent) for sent in sents]\n",
    "        sents = pad_sequence(sents, batch_first=True, padding_value=word_id['<pad>']).long()\n",
    "        return sents, torch.LongTensor(lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "    def __init__(self, sents, tags=None, test=False):\n",
    "        self.sents = sents\n",
    "        self.tags = tags\n",
    "        self.test = test\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sents)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.test:\n",
    "            return torch.LongTensor(tokenize(self.sents[idx], word_id))\n",
    "        else:\n",
    "            return torch.LongTensor(tokenize(self.sents[idx], word_id)), torch.LongTensor([tag_id[tag] for tag in self.tags[idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "class Trainer():\n",
    "    def __init__(self, model, dataloader, lr_scheduler, optimizer, criterion, epoches=30, device=None, freq=10):\n",
    "        self.model = model\n",
    "        self.dataloader = dataloader\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.epoches = epoches\n",
    "        self.device = device if device else 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.freq = freq\n",
    "    \n",
    "    def train(self):\n",
    "        self.model.to(self.device)\n",
    "        self.criterion.to(self.device)\n",
    "        self.model.train()\n",
    "        for epoch in tqdm(range(self.epoches)):\n",
    "            total_loss = 0\n",
    "            for sents, lengths, tags in self.dataloader:\n",
    "                sents, lengths, tags = sents.to(self.device, non_blocking=True), lengths, tags.to(self.device, non_blocking=True)\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(sents, lengths)\n",
    "                outputs = outputs.view(-1, outputs.shape[-1])\n",
    "                tags = tags.view(-1)\n",
    "                loss = self.criterion(outputs, tags)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "            self.lr_scheduler.step()\n",
    "            if epoch % self.freq == 0:\n",
    "                print(f'Epoch {epoch+1}/{self.epoches}, Loss: {total_loss/len(self.dataloader)}')\n",
    "    \n",
    "    def val(self, dataloader, name):\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        with open(name, 'w') as f:\n",
    "            with torch.no_grad():\n",
    "                for sents, lengths, tags in dataloader:\n",
    "                    sents, lengths, tags = sents.to(self.device, non_blocking=True), lengths, tags.to(self.device, non_blocking=True)\n",
    "                    outputs = self.model(sents, lengths)\n",
    "                    _, predicted = torch.max(outputs, 2)\n",
    "                    sents = sents.cpu().numpy()\n",
    "                    predicted = predicted.cpu().numpy()\n",
    "                    tags = tags.cpu().numpy()\n",
    "                    lengths = lengths.cpu().numpy()\n",
    "                    for i in range(len(sents)):\n",
    "                        for j in range(lengths[i]):\n",
    "                            f.write(f'{j+1} {word_lookup[sents[i][j]]} {tag_lookup[tags[i][j]]} {tag_lookup[predicted[i][j]]}\\n')\n",
    "                        f.write('\\n')\n",
    "                        \n",
    "    def test(self, dataloader, name):\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        with open(name, 'w') as f:\n",
    "            with torch.no_grad():\n",
    "                for sents, lengths in dataloader:\n",
    "                    sents, lengths = sents.to(self.device, non_blocking=True), lengths\n",
    "                    outputs = self.model(sents, lengths)\n",
    "                    _, predicted = torch.max(outputs, 2)\n",
    "                    sents = sents.cpu().numpy()\n",
    "                    predicted = predicted.cpu().numpy()\n",
    "                    lengths = lengths.cpu().numpy()\n",
    "                    for i in range(len(sents)):\n",
    "                        for j in range(lengths[i]):\n",
    "                            f.write(f'{j+1} {word_lookup[sents[i][j]]} {tag_lookup[predicted[i][j]]}\\n')\n",
    "                        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Bidirectional LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, target_size, num_layer=1, dropout=0.33, init_embedding=None):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        if init_embedding is not None:\n",
    "            self.word_embeddings = nn.Embedding.from_pretrained(init_embedding, padding_idx=word_id['<pad>'], freeze=False)\n",
    "        else:\n",
    "            self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=word_id['<pad>'])\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layer, bidirectional=True, batch_first=True, dropout=0 if num_layer == 1 else dropout)\n",
    "        self.dropout = nn.Dropout(dropout) if num_layer == 1 else nn.Identity()\n",
    "        num_direction = 2 if self.lstm.bidirectional else 1\n",
    "        self.linear = nn.Linear(hidden_dim * num_direction, output_dim)\n",
    "        self.ELU = nn.ELU()\n",
    "        self.classifier = nn.Linear(output_dim, target_size)\n",
    "    \n",
    "    def forward(self, sentence, lengths):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embeds, lengths, batch_first=True, enforce_sorted=False)\n",
    "        lstm_out, _ = self.lstm(packed)\n",
    "        lstm_out, _ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        output = self.linear(lstm_out)\n",
    "        output = self.ELU(output)\n",
    "        tag_space = self.classifier(output)\n",
    "        return tag_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:03<03:02,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.944644365270259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:38<02:17,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, Loss: 0.11501487896982897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [01:14<01:42,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50, Loss: 0.018057272090750226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [01:52<01:13,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50, Loss: 0.0054055079186366775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [02:32<00:35,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50, Loss: 0.003789166355568726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:07<00:00,  3.76s/it]\n"
     ]
    }
   ],
   "source": [
    "epoches = 50\n",
    "batch_size = 128\n",
    "torch.manual_seed(0)\n",
    "\n",
    "NERDataset_train = NERDataset(sents_train, tags_train)\n",
    "dataloader_train = DataLoader(NERDataset_train, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, num_workers=8)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = BiLSTM(len(word_id), 100, 256, 128, len(tag_id), num_layer=1, dropout=0.33)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tag_id['<pad>'])\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1, momentum=0.99, weight_decay=1e-4)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epoches, eta_min=1e-2)\n",
    "\n",
    "trainer = Trainer(model, dataloader_train, lr_scheduler, optimizer, criterion, epoches=epoches, device=device)\n",
    "trainer.train()\n",
    "torch.save(model, 'blstm1.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dev validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 51577 tokens with 5942 phrases; found: 5349 phrases; correct: 4547.\n",
      "accuracy:  96.11%; precision:  85.01%; recall:  76.52%; FB1:  80.54\n",
      "              LOC: precision:  92.63%; recall:  84.21%; FB1:  88.22  1670\n",
      "             MISC: precision:  86.12%; recall:  78.09%; FB1:  81.91  836\n",
      "              ORG: precision:  78.35%; recall:  72.86%; FB1:  75.50  1247\n",
      "              PER: precision:  81.64%; recall:  70.74%; FB1:  75.80  1596\n"
     ]
    }
   ],
   "source": [
    "NERDataset_dev = NERDataset(sents_dev, tags_dev)\n",
    "dataloader_dev = DataLoader(NERDataset_dev, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, num_workers=8)\n",
    "trainer.val(dataloader_dev, 'dev1.out')\n",
    "!perl conll03eval < dev1.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_test, _ = read_data('data/test', test=True)\n",
    "NERDataset_test = NERDataset(sents_test, test=True)\n",
    "dataloader_test = DataLoader(NERDataset_test, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, num_workers=8)\n",
    "trainer.test(dataloader_test, 'test1.out')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using GloVe word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load GloVe weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = pd.read_csv('./glove.6B.100d.gz', sep=\" \", quoting=3, header=None, index_col=0)\n",
    "glove_dict = {k: v.values for k, v in glove.T.items()}\n",
    "glove_mat = np.array([glove_dict[k] for k in glove_dict])\n",
    "glove_dict['<pad>'] = np.zeros(100)\n",
    "glove_dict['<unk>'] = np.mean(glove_mat, axis=0)\n",
    "init_embedding = torch.tensor(np.array([glove_dict[word_lookup[i]] if word_lookup[i] in glove_dict else\n",
    "                               glove_dict[word_lookup[i].lower()] + 5e-3 if word_lookup[i].lower() in glove_dict else glove_dict['<unk>']\n",
    "                               for i in range(len(word_id))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:04<03:22,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.9155444810956211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:45<02:40,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, Loss: 0.5344660595311956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [01:26<01:59,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50, Loss: 0.5134784089306653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [02:07<01:18,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50, Loss: 0.5075996149394472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [02:48<00:36,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50, Loss: 0.504991847074638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:23<00:00,  4.06s/it]\n"
     ]
    }
   ],
   "source": [
    "epoches = 50\n",
    "batch_size = 128\n",
    "torch.manual_seed(0)\n",
    "\n",
    "NERDataset_train = NERDataset(sents_train, tags_train)\n",
    "dataloader_train = DataLoader(NERDataset_train, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, num_workers=8)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = BiLSTM(len(word_id), 100, 256, 128, len(tag_id), num_layer=1, dropout=0.33, init_embedding=init_embedding.float())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tag_id['<pad>'], label_smoothing=0.1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1, momentum=0.99, nesterov=True)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epoches, eta_min=8e-2)\n",
    "\n",
    "trainer = Trainer(model, dataloader_train, lr_scheduler, optimizer, criterion, epoches=epoches, device=device)\n",
    "trainer.train()\n",
    "torch.save(model, 'blstm2.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dev validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 51577 tokens with 5942 phrases; found: 5960 phrases; correct: 5404.\n",
      "accuracy:  98.23%; precision:  90.67%; recall:  90.95%; FB1:  90.81\n",
      "              LOC: precision:  93.97%; recall:  94.99%; FB1:  94.48  1857\n",
      "             MISC: precision:  85.05%; recall:  83.95%; FB1:  84.50  910\n",
      "              ORG: precision:  84.88%; recall:  86.20%; FB1:  85.53  1362\n",
      "              PER: precision:  94.43%; recall:  93.87%; FB1:  94.15  1831\n"
     ]
    }
   ],
   "source": [
    "NERDataset_dev = NERDataset(sents_dev, tags_dev)\n",
    "dataloader_dev = DataLoader(NERDataset_dev, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, num_workers=8)\n",
    "trainer.val(dataloader_dev, 'dev2.out')\n",
    "!perl conll03eval < dev2.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_test, _ = read_data('data/test', test=True)\n",
    "NERDataset_test = NERDataset(sents_test, test=True)\n",
    "dataloader_test = DataLoader(NERDataset_test, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, num_workers=8)\n",
    "trainer.test(dataloader_test, 'test2.out')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM-CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create character vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_id = {}\n",
    "char_id['<pad>'] = 0\n",
    "char_id['<unk>'] = 1\n",
    "for i in range(len(sents)):\n",
    "    for j in range(len(sents[i])):\n",
    "        for c in sents[i][j]:\n",
    "            if c not in char_id:\n",
    "                char_id[c] = len(char_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Char Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_char(sent, char_id):\n",
    "    tokenized_char = []\n",
    "    for word in sent:\n",
    "        word_char = []\n",
    "        for c in word:\n",
    "            if c in char_id:\n",
    "                word_char.append(char_id[c])\n",
    "            else:\n",
    "                word_char.append(char_id['<unk>'])\n",
    "        word_char = torch.LongTensor(word_char)\n",
    "        tokenized_char.append(word_char)\n",
    "    return tokenized_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharDataset(Dataset):\n",
    "    def __init__(self, sents, tags=None, test=False):\n",
    "        self.sents = sents\n",
    "        self.tags = tags\n",
    "        self.test = test\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sents)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        from torch.nn.utils.rnn import pad_sequence\n",
    "        if self.test:\n",
    "            return torch.LongTensor(tokenize(self.sents[idx], word_id)), \\\n",
    "                torch.LongTensor(pad_sequence(tokenize_char(self.sents[idx], char_id), batch_first=True, padding_value=char_id['<pad>']))\n",
    "        else:\n",
    "            return torch.LongTensor(tokenize(self.sents[idx], word_id)), torch.LongTensor([tag_id[tag] for tag in self.tags[idx]]), \\\n",
    "                torch.LongTensor(pad_sequence(tokenize_char(self.sents[idx], char_id), batch_first=True, padding_value=char_id['<pad>']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_char(batch):\n",
    "    from torch.nn.utils.rnn import pad_sequence\n",
    "    import torch.nn.functional as F\n",
    "    if isinstance(batch[0], tuple) and len(batch[0]) == 3:\n",
    "        sents, tags, chars = zip(*batch)\n",
    "        lengths = [len(sent) for sent in sents]\n",
    "        sents = pad_sequence(sents, batch_first=True, padding_value=word_id['<pad>']).long()\n",
    "        tags = pad_sequence(tags, batch_first=True).long()\n",
    "        max_word_len = max(char.shape[1] for char in chars)\n",
    "        max_seq_len = sents.shape[1]\n",
    "        chars = torch.stack([F.pad(char, (0, max_word_len - char.shape[1], 0, max_seq_len - char.shape[0]), value=char_id['<pad>']) for char in chars])\n",
    "        return sents, torch.LongTensor(lengths), tags, chars\n",
    "    else:\n",
    "        sents, chars = zip(*batch)\n",
    "        lengths = [len(sent) for sent in sents]\n",
    "        sents = pad_sequence(sents, batch_first=True, padding_value=word_id['<pad>']).long()\n",
    "        max_word_len = max(char.shape[1] for char in chars)\n",
    "        max_seq_len = sents.shape[1]\n",
    "        chars = torch.stack([F.pad(char, (0, max_word_len - char.shape[1], 0, max_seq_len - char.shape[0]), value=char_id['<pad>']) for char in chars])\n",
    "        return sents, torch.LongTensor(lengths), chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharBiLSTM(BiLSTM):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, target_size, char_vocab_size, char_embedding_dim, num_layer=1, dropout=0.33, init_embedding=None):\n",
    "        super().__init__(vocab_size, embedding_dim, hidden_dim, output_dim, target_size, num_layer, dropout, init_embedding)\n",
    "        self.char_embeddings = nn.Embedding(char_vocab_size, char_embedding_dim, padding_idx=char_id['<pad>'])\n",
    "        self.char_cnn = nn.Conv1d(char_embedding_dim, char_embedding_dim, 3, padding=1)\n",
    "        self.char_maxpool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.lstm = nn.LSTM(embedding_dim + char_embedding_dim, hidden_dim, num_layers=num_layer, \n",
    "                            bidirectional=True, batch_first=True, dropout=0 if num_layer == 1 else dropout)\n",
    "    \n",
    "    def forward(self, sentence, lengths, chars):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        char_embeds = self.char_embeddings(chars)\n",
    "        b, s, w, c = char_embeds.shape\n",
    "        char_embeds = char_embeds.view(b*s, w, c).permute(0, 2, 1)\n",
    "        char_embeds = self.char_cnn(char_embeds)\n",
    "        char_embeds = self.char_maxpool(char_embeds).squeeze(-1)\n",
    "        char_embeds = char_embeds.view(b, s, -1)\n",
    "        embeds = torch.cat([embeds, char_embeds], dim=-1)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embeds, lengths, batch_first=True, enforce_sorted=False)\n",
    "        lstm_out, _ = self.lstm(packed)\n",
    "        lstm_out, _ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        output = self.linear(lstm_out)\n",
    "        output = self.ELU(output)\n",
    "        tag_space = self.classifier(output)\n",
    "        return tag_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Char trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "class CharTrainer():\n",
    "    def __init__(self, model, dataloader, lr_scheduler, optimizer, criterion, epoches=30, device=None, freq=10):\n",
    "        self.model = model\n",
    "        self.dataloader = dataloader\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.epoches = epoches\n",
    "        self.device = device if device else 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.freq = freq\n",
    "    \n",
    "    def train(self):\n",
    "        self.model.to(self.device)\n",
    "        self.criterion.to(self.device)\n",
    "        self.model.train()\n",
    "        for epoch in tqdm(range(self.epoches)):\n",
    "            total_loss = 0\n",
    "            for sents, lengths, tags, chars in self.dataloader:\n",
    "                sents, lengths, tags, chars = sents.to(self.device, non_blocking=True), lengths, \\\n",
    "                    tags.to(self.device, non_blocking=True), chars.to(self.device, non_blocking=True)\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(sents, lengths, chars)\n",
    "                outputs = outputs.view(-1, outputs.shape[-1])\n",
    "                tags = tags.view(-1)\n",
    "                loss = self.criterion(outputs, tags)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "            self.lr_scheduler.step()\n",
    "            if epoch % self.freq == 0:\n",
    "                print(f'Epoch {epoch+1}/{self.epoches}, Loss: {total_loss/len(self.dataloader)}')\n",
    "    \n",
    "    def val(self, dataloader, name):\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        with open(name, 'w') as f:\n",
    "            with torch.no_grad():\n",
    "                for sents, lengths, tags, chars in dataloader:\n",
    "                    sents, lengths, tags, chars = sents.to(self.device, non_blocking=True), lengths, \\\n",
    "                        tags.to(self.device, non_blocking=True), chars.to(self.device, non_blocking=True)\n",
    "                    outputs = self.model(sents, lengths, chars)\n",
    "                    _, predicted = torch.max(outputs, 2)\n",
    "                    sents = sents.cpu().numpy()\n",
    "                    predicted = predicted.cpu().numpy()\n",
    "                    tags = tags.cpu().numpy()\n",
    "                    lengths = lengths.cpu().numpy()\n",
    "                    for i in range(len(sents)):\n",
    "                        for j in range(lengths[i]):\n",
    "                            f.write(f'{j+1} {word_lookup[sents[i][j]]} {tag_lookup[tags[i][j]]} {tag_lookup[predicted[i][j]]}\\n')\n",
    "                        f.write('\\n')\n",
    "                        \n",
    "    def test(self, dataloader, name):\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        with open(name, 'w') as f:\n",
    "            with torch.no_grad():\n",
    "                for sents, lengths, chars in dataloader:\n",
    "                    sents, lengths, chars = sents.to(self.device, non_blocking=True), lengths, chars.to(self.device, non_blocking=True)\n",
    "                    outputs = self.model(sents, lengths, chars)\n",
    "                    _, predicted = torch.max(outputs, 2)\n",
    "                    sents = sents.cpu().numpy()\n",
    "                    predicted = predicted.cpu().numpy()\n",
    "                    lengths = lengths.cpu().numpy()\n",
    "                    for i in range(len(sents)):\n",
    "                        for j in range(lengths[i]):\n",
    "                            f.write(f'{j+1} {word_lookup[sents[i][j]]} {tag_lookup[predicted[i][j]]}\\n')\n",
    "                        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:06<04:58,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.8771523373611902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:54<03:09,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, Loss: 0.5253389098886716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [01:43<02:21,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50, Loss: 0.5106210188340332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [02:32<01:32,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50, Loss: 0.506106627694631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [03:21<00:43,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50, Loss: 0.5042909095853062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [04:05<00:00,  4.90s/it]\n"
     ]
    }
   ],
   "source": [
    "epoches = 50\n",
    "batch_size = 128\n",
    "torch.manual_seed(0)\n",
    "\n",
    "CharDataset_train = CharDataset(sents_train, tags_train)\n",
    "dataloader_train = DataLoader(CharDataset_train, batch_size=batch_size, shuffle=True, collate_fn=collate_fn_char, num_workers=8)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = CharBiLSTM(len(word_id), 100, 256, 128, len(tag_id), len(char_id), 30, num_layer=1, dropout=0.33, init_embedding=init_embedding.float())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tag_id['<pad>'], label_smoothing=0.1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1, momentum=0.99, nesterov=True)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epoches, eta_min=8e-2)\n",
    "\n",
    "trainer = CharTrainer(model, dataloader_train, lr_scheduler, optimizer, criterion, epoches=epoches, device=device)\n",
    "trainer.train()\n",
    "torch.save(model, 'blstm-cnn.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEV validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 51577 tokens with 5942 phrases; found: 6040 phrases; correct: 5507.\n",
      "accuracy:  98.64%; precision:  91.18%; recall:  92.68%; FB1:  91.92\n",
      "              LOC: precision:  95.05%; recall:  95.10%; FB1:  95.07  1838\n",
      "             MISC: precision:  86.45%; recall:  87.20%; FB1:  86.83  930\n",
      "              ORG: precision:  83.84%; recall:  88.22%; FB1:  85.97  1411\n",
      "              PER: precision:  95.27%; recall:  96.25%; FB1:  95.76  1861\n"
     ]
    }
   ],
   "source": [
    "CharDataset_dev = CharDataset(sents_dev, tags_dev)\n",
    "dataloader_dev = DataLoader(CharDataset_dev, batch_size=batch_size, shuffle=False, collate_fn=collate_fn_char, num_workers=8)\n",
    "trainer.val(dataloader_dev, 'dev-cnn.out')\n",
    "!perl conll03eval < dev-cnn.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_test, _ = read_data('data/test', test=True)\n",
    "CharDataset_test = CharDataset(sents_test, test=True)\n",
    "dataloader_test = DataLoader(CharDataset_test, batch_size=batch_size, shuffle=False, collate_fn=collate_fn_char, num_workers=8)\n",
    "trainer.test(dataloader_test, 'pred')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
